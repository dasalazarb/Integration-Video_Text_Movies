{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LM06au3zXved"
   },
   "outputs": [],
   "source": [
    "# Correr para reiniciar Kernel y la sesion.\n",
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWqnCHCyYBuQ"
   },
   "source": [
    "# Proyecto Final (Image + Text + Multi-Modal (Image + Text))\n",
    "\n",
    "### Curso Deep Learning y Redes Neuronales - MIIA4406_01\n",
    "\n",
    "#### Universidad de los Andes\n",
    "\n",
    "Integrantes:\n",
    "\n",
    "|Nombre|Codigo|\n",
    "|---------------------|---------------------|\n",
    "|Saby Espinel|*201215868*|\n",
    "|Diego Salazar|*201628925*| <br>\n",
    "<br>\n",
    "______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCzIzhFShSRO"
   },
   "source": [
    "## Verificacion de uso de 'GPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1532207359711,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "dAVco1aoYLAv",
    "outputId": "1baa060c-9ad8-4cf3-a32c-c3dbf5a71d72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 17386240137765768407, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11285974221\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8471661676241955885\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar que se esta usando GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uKtjL4TEhSTD"
   },
   "source": [
    "# >>> Librerias y Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2659,
     "status": "ok",
     "timestamp": 1532207367359,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "adtK2axjhSTE",
    "outputId": "e42427aa-405e-42be-fa2e-b326cb037920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.23.4)\n"
     ]
    }
   ],
   "source": [
    "##### Para cargar en Jupyter y CoLab #####\n",
    "!pip install tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "#from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "#from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Text processing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import History\n",
    "\n",
    "## Image\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dropout, Dense, Input, BatchNormalization, merge, Merge\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Iv98d79XhSTI"
   },
   "outputs": [],
   "source": [
    "##### Solo para Colab #####\n",
    "!pip install -U -q PyDrive\n",
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8aLKhd8zhSTK"
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1532207378571,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "j4cEpSUtS_gP",
    "outputId": "b3362a3a-3619-4ca4-b31e-1564fa145eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Control de parametros\n",
    "def controlParam(varTrain, path, max_review_length, top_words):\n",
    "  varTrain = varTrain\n",
    "  path = path\n",
    "  max_review_length = max_review_length\n",
    "  top_words = top_words\n",
    "  return varTrain, path, max_review_length, top_words\n",
    "\n",
    "# Para text detecta lemmas\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def split_into_lemmas(text):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    return [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "  \n",
    "# Para text detecta stemming\n",
    "def split_into_stem(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yuk_L7CDhSTT"
   },
   "source": [
    "******************************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUfPGEl9uQLc"
   },
   "source": [
    "# >>> Read dataTraining and dataTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1075,
     "status": "ok",
     "timestamp": 1532192846983,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "sBw6kSHt79V7",
    "outputId": "17955083-598a-4ba5-b3ae-ae840b077c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: ImageColab.ipynb, id: 1QI4l_c2wejdKDavNVdmMz6DSP0es2Jf2\n",
      "title: Resultados.xlsx, id: 1Lykn5EEY4RTyTesTN6f5d0LDm1AqIuGv\n",
      "title: pred_genres_img_RF.csv, id: 1l734WEkdZIeCUxGqJw_i0czo1bfm12IR\n",
      "title: Combinado.ipynb, id: 1l_nE9YS7I3lFqzqTT62X46Cm9rkb2Vwt\n",
      "title: ~$Resultados.xlsx, id: 1jvUOMuytd6qatDNqWg0NKSd_idSORy75\n",
      "title: ProcText (1).ipynb, id: 1k6E6N6jG6PCCwXzgoEKCskST6_HwCYAO\n",
      "title: ProcText.ipynb, id: 1d6n-hMm0W-Y9nXuUmGbfEACnmFmcUA2Z\n",
      "title: 0-CombinacionesText, id: 1Lk9Ek6fOIAV6v9ysYe8U8beBpvFEtbPfqVb6tyd-_I4\n",
      "title: features.pkl, id: 1gT_mDY7-1O9nwvWjFQj2qaVNhfl0TPFw\n",
      "title: Final Project.pptx, id: 17-MkUf4ltoGnoNHS8XhuI2PzG0Igd9YF\n",
      "title: Final Project, id: 1PIyDb9Q8kx5U-ShQRAAn1dXlVLRIPLs-VtXERlbpPW0\n",
      "title: TextColab.ipynb, id: 1sEAr0qGqVwDkmZJjw4o1UC3owfqykJma\n",
      "title: Text_Image_DeepLearning.ipynb, id: 1Cqw5bxyGIg6Pm-8hCAFuBh8-T-lwu_oi\n",
      "title: ExampleImgRF.ipynb, id: 1Pg2-wYIUr866PzKvUy8iXsstZT87uE6x\n",
      "title: Resultados_Jupyter, id: 1ANK5CbRmFQ6w-jbSzkkUO_bdjnUyXB6I\n",
      "title: Resultados_CoLab, id: 17Sk_UrlcK0BQIPAZ018Gjp8JxQZmm38p\n",
      "title: images_resize_gray, id: 1AuAOku0WZor-SegS9YWlg0gjqjlguogj\n",
      "title: images_resize_gray.zip, id: 1mcEsaLxakpcQqYZl1pe_qtIEh4FXj0Wx\n",
      "title: images_original, id: 16FnNSHtTQzQBgLbXKs77btkYJrWIH5IF\n",
      "title: images_original.zip, id: 1_Grjc2zdV2gHA7unPg_I7qTEdM6zl1Ok\n",
      "title: ExampleTextRF.ipynb, id: 1awW3xWv99qbvcMP1hWTIJjmdmKq8Ku42\n",
      "title: images.zip, id: 1NMIKcqCHJIDaQi4M9mbjrZf0qlpXtrO-\n",
      "title: images, id: 1pkD2K630_7_sqyt42vnbOYKVZrnyE-VQ\n",
      "title: dataTraining.csv, id: 1SKNGe6FFghASG38LjtUaoTrmozUibRCZ\n",
      "title: dataTesting.csv, id: 1JWWmvheWnofZl2zqY-7Gu2rJprceYB80\n",
      "title: .ipynb_checkpoints, id: 17KsfZFar28G8dXPBETs6cCpaAknZO3yP\n",
      "title: moviegenre.png, id: 1h6OU9y8Fwa-HqLMeVDAhLKO9Et6Bojmv\n",
      "title: README.md, id: 1ICVh_qZvcAXH36lytZyJiYgMFbocGgCd\n"
     ]
    }
   ],
   "source": [
    "##### Para CoLab #####\n",
    "# Verificacion de contenido de carpetas en el Drive con su respectivo ID\n",
    "#file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
    "file_list = drive.ListFile({'q': \"'1gX_xAhoYwIwmOVRd33lAuf4pCM3cChB6' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list:\n",
    "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m0s7D7nNuWDa"
   },
   "outputs": [],
   "source": [
    "##### Para CoLab #####\n",
    "trainDrive = drive.CreateFile({'id': '1SKNGe6FFghASG38LjtUaoTrmozUibRCZ'})\n",
    "trainDrive.GetContentFile('dataTraining.csv')\n",
    "dataTraining=pd.read_csv(\"dataTraining.csv\", index_col=0)\n",
    "\n",
    "testDrive = drive.CreateFile({'id': '1JWWmvheWnofZl2zqY-7Gu2rJprceYB80'})\n",
    "testDrive.GetContentFile('dataTesting.csv')\n",
    "dataTesting=pd.read_csv(\"dataTesting.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1532193252491,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "_5X45jOPuwz9",
    "outputId": "9d27124d-8b75-4b7e-f517-a095effd2c96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 1360.58it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((150, 5), (30, 3), (150, 256, 160, 1), 7895, (150, 24))"
      ]
     },
     "execution_count": 185,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fijar parametros de control\n",
    "varTrain, path, max_review_length, top_words = controlParam(varTrain = 150, # Numero de muestrar para usar\n",
    "             path = \"images/\", # Ruta donde estan almacenadas las imagenes\n",
    "             max_review_length = 1000, # Numero maximo de largo permitido\n",
    "             top_words = 100) # Maximo de palabras permitidas\n",
    "\n",
    "# Funcion para seleccionar una muestra de las imagenes de dataTraining y dataTesting\n",
    "def sampleData(dataTrain, dataTest, varTrain, varTest):\n",
    "  ix_train=np.random.choice(dataTrain.shape[0], varTrain)\n",
    "  ix_test=np.random.choice(dataTest.shape[0], varTest)\n",
    "  return dataTrain.iloc[ix_train], dataTest.iloc[ix_test]\n",
    "\n",
    "newDataTraining, newDataTesting  = sampleData(dataTraining, dataTesting, varTrain=varTrain, varTest=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dT_MhO5GXMMx"
   },
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1532186069795,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "R2K3Gex0XKgF",
    "outputId": "af17c54d-6d1c-4cb6-8525-44aa7ecab577"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create count vectorizer with ngrams\n",
    "#vect = CountVectorizer(analyzer=split_into_lemmas, ngram_range=(1, 2), max_features=1000, stop_words='english') # LEMMAS\n",
    "#vect = CountVectorizer(analyzer=split_into_stem, ngram_range=(1, 2), max_features=1000, stop_words='english') # STEM\n",
    "vect = CountVectorizer(analyzer=\"word\", ngram_range=(1, 2), max_features=max_review_length, stop_words='english')\n",
    "X_dtm = vect.fit_transform(newDataTraining['plot'])\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x31avan3hSTV"
   },
   "source": [
    "# >>> Read Images CoLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1500,
     "status": "ok",
     "timestamp": 1532186077518,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "xs5IbjQxSOJN",
    "outputId": "0c12461d-50ee-40df-d612-d61d98cf8aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalab  dataTesting.csv  dataTraining.csv  nltk_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gh9WjLSJdyqQ"
   },
   "source": [
    "# Gray Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RbH9N1sZhSTa"
   },
   "outputs": [],
   "source": [
    "##### Para CoLab #####\n",
    "trainDrive = drive.CreateFile({'id': '1SKNGe6FFghASG38LjtUaoTrmozUibRCZ'})\n",
    "trainDrive.GetContentFile('dataTraining.csv')\n",
    "dataTraining=pd.read_csv(\"dataTraining.csv\", index_col=0)\n",
    "\n",
    "testDrive = drive.CreateFile({'id': '1JWWmvheWnofZl2zqY-7Gu2rJprceYB80'})\n",
    "testDrive.GetContentFile('dataTesting.csv')\n",
    "dataTesting=pd.read_csv(\"dataTesting.csv\", index_col=0)\n",
    "\n",
    "# Download a file based on its file ID.\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "##### Para CoLab #####\n",
    "imagesGray = drive.CreateFile({'id': '1mcEsaLxakpcQqYZl1pe_qtIEh4FXj0Wx'})\n",
    "imagesGray.GetContentFile('images_resize_gray.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1429,
     "status": "ok",
     "timestamp": 1532207389248,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "HNXYu6oex96L",
    "outputId": "1b64f93a-0fcd-402a-9866-3a91694ded78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalab\t\t dataTraining.csv    images_resize_gray.zip\n",
      "dataTesting.csv  images_resize_gray  nltk_data\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CWPZM1IAhSTN"
   },
   "outputs": [],
   "source": [
    "# Tome las primeras 1025 + 1055 imagenes\n",
    "!unzip -o images_resize_gray.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1532207406753,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "WVsUHNs-8Tax",
    "outputId": "82016939-35a9-434f-aba8-3d1fc33cf81c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1678.16it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1000, 5), (30, 3), (1000, 256, 160, 1), 7895, (1000, 24))"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fijar parametros de control\n",
    "varTrain, path, max_review_length, top_words = controlParam(varTrain = 1000, # Numero de muestrar para usar\n",
    "             path = \"images/\", # Ruta donde estan almacenadas las imagenes\n",
    "             max_review_length = 1000, # Numero maximo de largo permitido\n",
    "             top_words = 100) # Maximo de palabras permitidas\n",
    "\n",
    "# Funcion para seleccionar una muestra de las imagenes de dataTraining y dataTesting\n",
    "def sampleData(dataTrain, dataTest, varTrain, varTest):\n",
    "  ix_train=np.random.choice(dataTrain.shape[0], varTrain)\n",
    "  ix_test=np.random.choice(dataTest.shape[0], varTest)\n",
    "  return dataTrain.iloc[ix_train], dataTest.iloc[ix_test]\n",
    "\n",
    "newDataTraining, newDataTesting  = sampleData(dataTraining, dataTesting, varTrain=varTrain, varTest=30)\n",
    "\n",
    "path='images_resize_gray/'\n",
    "# Training\n",
    "images_training = []\n",
    "newIndexTrain = []\n",
    "for i in tqdm(newDataTraining.index):\n",
    "    #path =\"C:/Users/da.salazarb/Google Drive (dasalazarb@unal.edu.co)/AppliedDeepLearningClass-master/finalProject/\"\n",
    "    #images_training.append(io.imread(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg')).flatten())\n",
    "    images_training.append(io.imread(os.path.join(path, str(i) + '_resize_gray.jpeg')))\n",
    "    newIndexTrain.append(i)\n",
    "    #images_training.append(io.imread(os.path.join(path, str(i) + \".jpeg\")).flatten())\n",
    "    \n",
    "images_training = np.stack(images_training)\n",
    "images_training = images_training.reshape(images_training.shape[0],images_training.shape[1], images_training.shape[2], 1)\n",
    "#images_training = images_training.reshape(images_training.shape[0], 1, images_training.shape[1], images_training.shape[2])\n",
    "images_training = images_training.astype('float32')\n",
    "images_training /= 255\n",
    "    \n",
    "\n",
    "    \n",
    "newDataTraining = dataTraining.loc[newIndexTrain]\n",
    "newDataTraining['genres'] = newDataTraining['genres'].map(lambda x: eval(str(x)))\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(newDataTraining['genres'])\n",
    "newDataTraining.shape, newDataTesting.shape, images_training.shape, dataTraining.shape[0], y_genres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3031,
     "status": "ok",
     "timestamp": 1532207415029,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "_TyWU0BJ2XKh",
    "outputId": "5c826a10-30eb-49ba-891e-566ff9ea0c45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3383/3383 [00:02<00:00, 1622.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3383, 256, 160, 1), 3383)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='images_resize_gray/'\n",
    "# Testing\n",
    "images_testing  = []\n",
    "newIndexTest = []\n",
    "for i in tqdm(dataTesting.index):\n",
    "    #images_testing.append(io.imread(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg')).flatten())\n",
    "    #images_testing.append(io.imread(os.path.join(path, str(i) + '_resize_gray.jpeg')).flatten())\n",
    "    images_testing.append(io.imread(os.path.join(path, str(i) + '_resize_gray.jpeg')))\n",
    "    newIndexTest.append(i)\n",
    "\n",
    "images_testing = np.stack(images_testing)\n",
    "#images_testing = images_testing.reshape(images_testing.shape[0],images_testing.shape[1], images_testing.shape[2], 1)\n",
    "images_testing = images_testing.reshape(images_testing.shape[0], images_testing.shape[1], images_testing.shape[2], 1)\n",
    "images_testing = images_testing.astype('float32')\n",
    "images_testing /= 255\n",
    "\n",
    "images_testing.shape, dataTesting.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bybHaHppdvQN"
   },
   "source": [
    "# Color Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QZK5uOuOduIF"
   },
   "outputs": [],
   "source": [
    "# Download a file based on its file ID.\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "##### Para CoLab #####\n",
    "imagesColor = drive.CreateFile({'id': '1_Grjc2zdV2gHA7unPg_I7qTEdM6zl1Ok'})\n",
    "imagesColor.GetContentFile('images_original.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1719,
     "status": "ok",
     "timestamp": 1532186175391,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "UHLF73hsx_vq",
    "outputId": "cf9cde78-4723-4275-b3f8-9ceb2cf60ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalab  dataTesting.csv  dataTraining.csv  images_original.zip  nltk_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-lSlSwWmeCXt"
   },
   "outputs": [],
   "source": [
    "# Tome las primeras 1025 + 1055 imagenes\n",
    "!unzip -o images_original.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21402,
     "status": "ok",
     "timestamp": 1532186268791,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "Y1wkf04bqq19",
    "outputId": "dfcb272b-25c2-49d9-c432-aae40655ecf4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 370/500 [00:14<00:05, 25.92it/s]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:2274: DecompressionBombWarning: Image size (97200000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "100%|██████████| 500/500 [00:20<00:00, 23.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((500, 224, 224, 3), 7895, (500, 5))"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='images/'\n",
    "# Training\n",
    "images_training = []\n",
    "newIndexTrain = []\n",
    "for i in tqdm(newDataTraining.index):\n",
    "    #path =\"C:/Users/da.salazarb/Google Drive (dasalazarb@unal.edu.co)/AppliedDeepLearningClass-master/finalProject/\"\n",
    "    #images_training.append(io.imread(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg')).flatten())\n",
    "    #images_training.append(io.imread(os.path.join(path, str(i) + '_resize_gray.jpeg')))\n",
    "    archivoImg = cv2.resize(io.imread(os.path.join(path, str(i) + \".jpeg\")), (224, 224))\n",
    "    if len(archivoImg.shape) == 3:\n",
    "      images_training.append(archivoImg)\n",
    "      newIndexTrain.append(i)\n",
    "images_training = np.stack(images_training)\n",
    "images_training.shape, dataTraining.shape[0], newDataTraining.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117287,
     "status": "ok",
     "timestamp": 1532186390920,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "sTpCLQKTMoKW",
    "outputId": "c5cbe1e7-69f6-4a1f-e1f0-c1490170c606"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 102/3383 [00:02<01:22, 39.74it/s]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:2274: DecompressionBombWarning: Image size (97143904 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      " 61%|██████    | 2049/3383 [01:10<00:46, 28.90it/s]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:2274: DecompressionBombWarning: Image size (97200000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      " 61%|██████    | 2067/3383 [01:13<00:47, 27.99it/s]100%|██████████| 3383/3383 [01:56<00:00, 28.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3383, 224, 224, 3), 3383)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='images/'\n",
    "# Training\n",
    "images_testing = []\n",
    "newIndexTest = []\n",
    "for i in tqdm(dataTesting.index):\n",
    "    #path =\"C:/Users/da.salazarb/Google Drive (dasalazarb@unal.edu.co)/AppliedDeepLearningClass-master/finalProject/\"\n",
    "    #images_training.append(io.imread(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg')).flatten())\n",
    "    #images_training.append(io.imread(os.path.join(path, str(i) + '_resize_gray.jpeg')))\n",
    "    archivoImg = cv2.resize(io.imread(os.path.join(path, str(i) + \".jpeg\")), (224, 224))\n",
    "    if len(archivoImg.shape) == 2:\n",
    "      archivoImg = cv2.cvtColor(archivoImg,cv2.COLOR_GRAY2RGB)\n",
    "    images_testing.append(archivoImg)\n",
    "    newIndexTest.append(i)\n",
    "    #print(i)\n",
    "images_testing = np.stack(images_testing)\n",
    "images_testing.shape, dataTesting.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54LCwTqJTleW"
   },
   "source": [
    "# Create *'y'* Colab (img + text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CHt-sNGyH4je"
   },
   "outputs": [],
   "source": [
    "newDataTraining = dataTraining.loc[newIndexTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1532191145760,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "tY60NTsBUtfa",
    "outputId": "aa47f91a-2df6-478e-b56d-8df6b49548a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(350, 23)"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDataTraining['genres'] = newDataTraining['genres'].map(lambda x: eval(str(x)))\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(newDataTraining['genres'])\n",
    "y_genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkNQfiunhSU7"
   },
   "source": [
    "# Deep Neural Networks Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25098,
     "status": "ok",
     "timestamp": 1532186438651,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "KKBRhvZyhSU7",
    "outputId": "850f757b-a195-4e10-cb65-f595e74fe835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574717952/574710816 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "base_modelVGG19 = VGG19(weights='imagenet')\n",
    "base_modelVGG19.compile(optimizer=\"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62558,
     "status": "ok",
     "timestamp": 1532035355438,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "Ux0MnTOH3aVl",
    "outputId": "ac55ffbd-da8f-4b75-a6b5-f6068710de71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "225214464/225209952 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "base_modelInceptionResNetV2 = InceptionResNetV2(weights='imagenet')\n",
    "base_modelInceptionResNetV2.compile(optimizer=\"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LvK8D0QMhSVE"
   },
   "outputs": [],
   "source": [
    "def preTrainedModel(base_model):\n",
    "  x = base_model.output\n",
    "  x = Dense(256)(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(24)(x)\n",
    "  x = Activation(\"sigmoid\")(x)\n",
    "  model = Model(inputs=base_model.input, outputs=x)\n",
    "  model.compile(optimizer=\"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31592,
     "status": "ok",
     "timestamp": 1532187868298,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "aqRHE2cthSVG",
    "outputId": "e43c2c1d-56fb-46f0-d734-fc702867717e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 8.7805 - acc: 0.0280\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 8.6554 - acc: 0.0660\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 8.5428 - acc: 0.1000\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 8.4036 - acc: 0.1080\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 8.2653 - acc: 0.1440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e74827710>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = preTrainedModel(base_modelInceptionResNetV2)\n",
    "model = preTrainedModel(base_modelVGG19)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "#model.fit_generator(train_datagen.flow(images_training, y_genres, batch_size=32), steps_per_epoch=len(images_training) / 32, epochs=5)\n",
    "\n",
    "#model.fit(X_train, y_train_genres, epochs=5, validation_data=[X_test, y_test_genres])\n",
    "model.fit(x=images_training, y=y_genres, epochs=5, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lmro8WjlcUhd"
   },
   "source": [
    "# Prediction on dataTesting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OfPHd5vucUhe"
   },
   "outputs": [],
   "source": [
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = model.predict(images_testing)\n",
    "#y_pred_test_genres = modeltune.predict_proba(images_testing)\n",
    "\n",
    "pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols).to_csv('pred_genres_img_RF.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_So2YdPEcUhg"
   },
   "outputs": [],
   "source": [
    "files.download('pred_genres_img_RF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9t0cBLPhSVJ"
   },
   "source": [
    "# Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mQNr_ql5dP4j"
   },
   "outputs": [],
   "source": [
    "base_modelVGG19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58870,
     "status": "ok",
     "timestamp": 1532188081683,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "3OF5JPOwhSVK",
    "outputId": "e4aa22bf-d5fa-4d63-e181-e57b19c69c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 8.2620 - acc: 0.1660\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 7.8114 - acc: 0.2000\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 7.8108 - acc: 0.1980\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 7.7641 - acc: 0.1740\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 7.7588 - acc: 0.1660\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 7.7262 - acc: 0.1700\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 7.7313 - acc: 0.1680\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 7.7324 - acc: 0.1700\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 7.7256 - acc: 0.1720\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 7.6905 - acc: 0.1700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e723a47f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fineTune(base_model):\n",
    "  x = base_model.output\n",
    "  #x = Flatten()(x)\n",
    "  x = Dense(256)(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(256)(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(256)(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(256)(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(24)(x)\n",
    "  x = Activation(\"sigmoid\")(x)\n",
    "  model = Model(inputs=base_model.input, outputs=x)\n",
    "  #model.compile(optimizer=\"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "  return model\n",
    "\n",
    "modeltune = fineTune(base_modelVGG19)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_modelVGG19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "modeltune.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "modeltune.fit(x=images_training, y=y_genres, epochs=5)\n",
    "\n",
    "# Vamos a escoger las layers de base_model para entrenarlas.\n",
    "for layer in modeltune.layers[:31]:\n",
    "   layer.trainable = False\n",
    "for layer in modeltune.layers[31:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# Re-compilamos el modelos para que estas modificaciones tengan efecto\n",
    "# Usamos SGD y un learning rate bajo\n",
    "from keras.optimizers import SGD\n",
    "modeltune.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# Entrenamos el modelo nuevamente Esta vez con todo \n",
    "#(esta vez ajustando los 2 primeros bloques de inicio junto a las capas superiores de Dense)\n",
    "modeltune.fit(x=images_training, y=y_genres, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQflic-iMFPY"
   },
   "source": [
    "# Prediction on dataTesting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mN4L3dRBMFPZ"
   },
   "outputs": [],
   "source": [
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = modeltune.predict(images_testing)\n",
    "#y_pred_test_genres = modeltune.predict_proba(images_testing)\n",
    "\n",
    "pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols).to_csv('pred_genres_img_RF.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "h4pF19pgMFPc"
   },
   "outputs": [],
   "source": [
    "files.download('pred_genres_img_RF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6c1aTzyKf3YU"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3k6-0HSohSVK"
   },
   "outputs": [],
   "source": [
    "def convoNet(activation=\"tanh\", optimizer=\"adam\", drop=.4, neuron=132):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"valid\", data_format=\"channels_last\", input_shape=(256, 160, 1)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "    #model.add(Conv2D(64, (3, 3)))\n",
    "    #model.add(Activation(activation))\n",
    "    #model.add(Dropout(drop))\n",
    "    #model.add(BatchNormalization(axis=1))\n",
    "    #model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(neuron))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(24))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1532194805926,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "mGbQXbPmjOym",
    "outputId": "2569b41e-aaaf-4ed1-94c9-12efbaa38f28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 256, 160, 1), (200, 24))"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_training.shape, y_genres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2869
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21470,
     "status": "error",
     "timestamp": 1532194940338,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "60uqRY5QWrN8",
    "outputId": "8f6bd71e-12a7-468b-ed26-765c48423d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [2464000,132] and type float\n\t [[Node: training_2/Adam/zeros_12 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2464000,132] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e3860130aab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvoNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_genres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2482\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [2464000,132] and type float\n\t [[Node: training_2/Adam/zeros_12 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2464000,132] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'training_2/Adam/zeros_12', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-e3860130aab6>\", line 2, in <module>\n    model.fit(x=images_training, y=y_genres, epochs=5, batch_size=50)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 1002, in fit\n    validation_steps=validation_steps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 992, in _make_train_function\n    loss=self.total_loss)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 457, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 457, in <listcomp>\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 693, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 1550, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2793, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [2464000,132] and type float\n\t [[Node: training_2/Adam/zeros_12 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2464000,132] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model = convoNet()\n",
    "model.fit(x=images_training, y=y_genres, epochs=5, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfRpTJeCrf5V"
   },
   "source": [
    "# Other CNN + Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hybHPi6Prd-9"
   },
   "outputs": [],
   "source": [
    "rows, cols = 256, 160\n",
    "def create_convnet():\n",
    "    import keras\n",
    "    input_shape = Input(shape=(rows, cols, 1))\n",
    "\n",
    "    tower_1 = Conv2D(20, (100, 5), padding='same', activation='relu')(input_shape)\n",
    "    tower_1 = MaxPooling2D((1, 11), strides=(1, 1), padding='same')(tower_1)\n",
    "\n",
    "    tower_2 = Conv2D(20, (100, 7), padding='same', activation='relu')(input_shape)\n",
    "    tower_2 = MaxPooling2D((1, 9), strides=(1, 1), padding='same')(tower_2)\n",
    "\n",
    "    tower_3 = Conv2D(20, (100, 10), padding='same', activation='relu')(input_shape)\n",
    "    tower_3 = MaxPooling2D((1, 6), strides=(1, 1), padding='same')(tower_3)\n",
    "\n",
    "    merged = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)\n",
    "    merged = Flatten()(merged)\n",
    "\n",
    "    out = Dense(200, activation='relu')(merged)\n",
    "    out = Dense(24, activation='sigmoid')(out)\n",
    "\n",
    "    model = Model(input_shape, out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2869
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 312599,
     "status": "error",
     "timestamp": 1532207988691,
     "user": {
      "displayName": "Diego Armando Salazar Barreto",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110062887053583561343"
     },
     "user_tz": 300
    },
    "id": "I15dxIxqr0AI",
    "outputId": "0099b0eb-8719-402f-f60e-e41b62a57683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2457600,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dense_8/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=2380272, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_5/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0cfe42589bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_convnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_genres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2482\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2457600,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dense_8/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=2380272, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_5/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense_8/random_uniform/RandomUniform', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-0cfe42589bd2>\", line 1, in <module>\n    model = create_convnet()\n  File \"<ipython-input-36-e271dc091853>\", line 18, in create_convnet\n    out = Dense(200, activation='relu')(merged)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 592, in __call__\n    self.build(input_shapes[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\", line 864, in build\n    constraint=self.kernel_constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 413, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/usr/local/lib/python3.6/dist-packages/keras/initializers.py\", line 217, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 3838, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_random_ops.py\", line 674, in random_uniform\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2457600,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dense_8/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=2380272, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_5/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "model = create_convnet()\n",
    "\n",
    "model.fit(images_training, y_genres, epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fObthWpxWzHb"
   },
   "source": [
    "# Prediction on dataTesting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gsHcc977WuDl"
   },
   "outputs": [],
   "source": [
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = model.predict_proba(images_testing)\n",
    "\n",
    "pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols).to_csv('pred_genres_img_RF.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "l88t4tooY2Aa"
   },
   "outputs": [],
   "source": [
    "files.download('pred_genres_img_RF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56TXfB3uuH4c"
   },
   "source": [
    "# Multi-modal Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5jbLoLOk8kHv"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(images_training)\n",
    "\n",
    "model = convoNet()\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(images_training, y_genres,\n",
    "                                 batch_size=100),\n",
    "                    epochs=2,\n",
    "                    workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTAPC8RHjbkB"
   },
   "source": [
    "# Prediction on dataTesting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "k0zl5Cl1jbkD"
   },
   "outputs": [],
   "source": [
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = model.predict_proba(images_testing)\n",
    "\n",
    "pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols).to_csv('pred_genres_img_RF.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iQK6OCikjbkG"
   },
   "outputs": [],
   "source": [
    "files.download('pred_genres_img_RF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLPLS_2nTjad"
   },
   "source": [
    "# Prediction for multi-modal Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jiXDD0BkTjam"
   },
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(dataTesting['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = model.predict_proba(X_test_dtm)\n",
    "\n",
    "pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols).to_csv('pred_genres_text_RF.csv', index_label='ID')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "uUfPGEl9uQLc",
    "dT_MhO5GXMMx",
    "bybHaHppdvQN",
    "54LCwTqJTleW",
    "gkNQfiunhSU7",
    "Lmro8WjlcUhd",
    "d9t0cBLPhSVJ",
    "UQflic-iMFPY",
    "6c1aTzyKf3YU",
    "fObthWpxWzHb"
   ],
   "default_view": {},
   "name": "ImageColab.ipynb",
   "provenance": [
    {
     "file_id": "1sEAr0qGqVwDkmZJjw4o1UC3owfqykJma",
     "timestamp": 1532023227639
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
